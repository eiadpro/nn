{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10272550,"sourceType":"datasetVersion","datasetId":6356021}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"provenance":[]}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\ntrain = pd.read_csv('/kaggle/input/data11234567/train.csv')\ntest = pd.read_csv('/kaggle/input/data11234567/test.csv')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-22T19:48:50.071355Z","iopub.execute_input":"2024-12-22T19:48:50.071674Z","iopub.status.idle":"2024-12-22T19:48:50.532682Z","shell.execute_reply.started":"2024-12-22T19:48:50.071651Z","shell.execute_reply":"2024-12-22T19:48:50.531637Z"},"id":"YiefCRvwmYYP"},"outputs":[],"execution_count":1},{"cell_type":"code","source":"train['Discussion'].isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T19:48:50.533988Z","iopub.execute_input":"2024-12-22T19:48:50.534264Z","iopub.status.idle":"2024-12-22T19:48:50.543811Z","shell.execute_reply.started":"2024-12-22T19:48:50.534242Z","shell.execute_reply":"2024-12-22T19:48:50.542943Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"EwRGKQssmYYR","outputId":"c0f85020-e037-4115-9073-db6b519f2361"},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"343"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"train = train.dropna(subset=['Discussion'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T19:48:50.545430Z","iopub.execute_input":"2024-12-22T19:48:50.545804Z","iopub.status.idle":"2024-12-22T19:48:50.565480Z","shell.execute_reply.started":"2024-12-22T19:48:50.545753Z","shell.execute_reply":"2024-12-22T19:48:50.564484Z"},"id":"PcI3KQqOmYYS"},"outputs":[],"execution_count":3},{"cell_type":"code","source":"train['Discussion'].isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T19:48:50.566865Z","iopub.execute_input":"2024-12-22T19:48:50.567146Z","iopub.status.idle":"2024-12-22T19:48:50.583406Z","shell.execute_reply.started":"2024-12-22T19:48:50.567113Z","shell.execute_reply":"2024-12-22T19:48:50.582580Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"hUw-synNmYYS","outputId":"a47edc1b-8b18-4cd6-bdd1-ef25c299bf7c"},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"file = open('/kaggle/input/data11234567/ClassesMap.txt','r')\nfile2 = file.read()\nfile.close()\nfile2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T19:48:50.584445Z","iopub.execute_input":"2024-12-22T19:48:50.584759Z","iopub.status.idle":"2024-12-22T19:48:50.599744Z","shell.execute_reply.started":"2024-12-22T19:48:50.584727Z","shell.execute_reply":"2024-12-22T19:48:50.599071Z"},"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"tjh8Zjw2mYYS","outputId":"5b060d26-b5c6-4904-b61c-5238d2f66d2c"},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"'Politics --> 0\\nSports --> 1\\nMedia --> 2\\nMarket & Economy --> 3\\nSTEM --> 4'"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"train['Category'].replace({\n    'Politics': 0,\n    'Sports': 1,\n    'Media': 2,\n    'Market & Economy': 3,\n    'STEM': 4\n}, inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T19:48:50.600653Z","iopub.execute_input":"2024-12-22T19:48:50.600969Z","iopub.status.idle":"2024-12-22T19:48:50.622064Z","shell.execute_reply.started":"2024-12-22T19:48:50.600937Z","shell.execute_reply":"2024-12-22T19:48:50.621177Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"xw1XdRTTmYYT","outputId":"f1e1afc5-5a77-4a57-ded2-9edefb488e5a"},"outputs":[],"execution_count":6},{"cell_type":"code","source":"train['Category'].head(7)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T19:48:50.622742Z","iopub.execute_input":"2024-12-22T19:48:50.623027Z","iopub.status.idle":"2024-12-22T19:48:50.628058Z","shell.execute_reply.started":"2024-12-22T19:48:50.623006Z","shell.execute_reply":"2024-12-22T19:48:50.627360Z"},"colab":{"base_uri":"https://localhost:8080/","height":303},"id":"zEalRF1FmYYT","outputId":"c7c13d30-df0c-438b-dff7-b5c221ca78b4"},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"0    1\n1    4\n2    4\n3    1\n4    0\n5    2\n6    2\nName: Category, dtype: int64"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"! pip install wordninja","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T19:48:50.630159Z","iopub.execute_input":"2024-12-22T19:48:50.630350Z","iopub.status.idle":"2024-12-22T19:48:53.923140Z","shell.execute_reply.started":"2024-12-22T19:48:50.630334Z","shell.execute_reply":"2024-12-22T19:48:53.922109Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"5eWyRLI1mYYT","outputId":"a4a592dc-d325-4a32-a442-12b286510c56"},"outputs":[{"name":"stdout","text":"Requirement already satisfied: wordninja in /usr/local/lib/python3.10/dist-packages (2.0.0)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"! pip install tensorflow","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T19:48:53.924683Z","iopub.execute_input":"2024-12-22T19:48:53.925038Z","iopub.status.idle":"2024-12-22T19:48:57.177992Z","shell.execute_reply.started":"2024-12-22T19:48:53.925006Z","shell.execute_reply":"2024-12-22T19:48:57.177108Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"CASaat2PmYYT","outputId":"0643226d-2459-44a0-acc5-d0873bc8ac10"},"outputs":[{"name":"stdout","text":"Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\nRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\nRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\nRequirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\nRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\nRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\nRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\nRequirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\nRequirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\nRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\nRequirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.8.1)\nRequirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\nRequirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.12.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.4)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import re\nimport wordninja\nimport nltk\n# stop_words = set([\"the\", \"and\", \"is\", \"in\", \"to\", \"a\", \"of\", \"for\", \"on\", \"with\", \"at\", \"by\", \"from\", \"this\", \"that\", \"it\",\"n\",\"nn\"])\ndef preprocess_text(text):\n    # Step 1: Convert to lowercase\n    text = text.lower()\n    # Step 2: Remove newlines (\\n)\n    text = text.replace('\\n', ' ')\n    # Step 3: Remove special characters and punctuations but keep numbers\n    text = re.sub(r'[^\\w\\s\\d]', '', text)\n    # Step 4: Apply WordNinja to split words longer than 10 characters\n    text = ' '.join([\n        ' '.join(wordninja.split(word)) if len(word) > 10 else word\n        for word in text.split()\n    ])\n    # text = ' '.join([word for word in text.split() if word not in stop_words])\n\n    return text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T19:48:57.179092Z","iopub.execute_input":"2024-12-22T19:48:57.179328Z","iopub.status.idle":"2024-12-22T19:48:57.943082Z","shell.execute_reply.started":"2024-12-22T19:48:57.179309Z","shell.execute_reply":"2024-12-22T19:48:57.942162Z"},"id":"Ch0fxEJKmYYT"},"outputs":[],"execution_count":10},{"cell_type":"code","source":"train['Discussion'] = train['Discussion'].apply(preprocess_text)\ntest['Discussion'] = test['Discussion'].apply(preprocess_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T19:48:57.944007Z","iopub.execute_input":"2024-12-22T19:48:57.944476Z","iopub.status.idle":"2024-12-22T19:49:05.996741Z","shell.execute_reply.started":"2024-12-22T19:48:57.944450Z","shell.execute_reply":"2024-12-22T19:49:05.996054Z"},"id":"s0RuseeQmYYU"},"outputs":[],"execution_count":11},{"cell_type":"code","source":"train['Discussion'].iloc[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T19:49:05.997517Z","iopub.execute_input":"2024-12-22T19:49:05.997729Z","iopub.status.idle":"2024-12-22T19:49:06.003014Z","shell.execute_reply.started":"2024-12-22T19:49:05.997711Z","shell.execute_reply":"2024-12-22T19:49:06.002231Z"},"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"dUFAqldnmYYU","outputId":"aa2b6995-4080-496c-bec9-76e34e91e28f"},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"'without sitting down and doing it manually you might try some scheduling software there are several here is one that you can download i havent tried it but it seems to do the job nn http www download com the league system pro 30007427 410505040 html tag pdp prod'"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"test['Discussion'].iloc[281]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T19:49:06.003733Z","iopub.execute_input":"2024-12-22T19:49:06.003952Z","iopub.status.idle":"2024-12-22T19:49:06.018365Z","shell.execute_reply.started":"2024-12-22T19:49:06.003935Z","shell.execute_reply":"2024-12-22T19:49:06.017691Z"},"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"mGaplzvEmYYU","outputId":"c47b59e1-aebf-48ab-e3fe-0e55864dfe7e"},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"'http www x rates com d usd mxn graph 120 html'"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"# List of words to remove\nremove_words = [\"http\", \"www\", \"com\"]\n\ndef remove_specific_words(text):\n    # Split the text into words and filter out the unwanted words\n    filtered_text = ' '.join([word for word in text.split() if word not in remove_words])\n    return filtered_text\n\n# Apply the function to both train and test DataFrames\ntrain['Discussion'] = train['Discussion'].apply(remove_specific_words)\ntest['Discussion'] = test['Discussion'].apply(remove_specific_words)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T19:49:06.019057Z","iopub.execute_input":"2024-12-22T19:49:06.019328Z","iopub.status.idle":"2024-12-22T19:49:06.332801Z","shell.execute_reply.started":"2024-12-22T19:49:06.019300Z","shell.execute_reply":"2024-12-22T19:49:06.331859Z"},"id":"69ks_W6hmYYU"},"outputs":[],"execution_count":14},{"cell_type":"code","source":"print(train['Discussion'].iloc[0])\nprint(\"......................................................................................\")\nprint(test['Discussion'].iloc[281])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T19:49:06.333845Z","iopub.execute_input":"2024-12-22T19:49:06.334073Z","iopub.status.idle":"2024-12-22T19:49:06.338964Z","shell.execute_reply.started":"2024-12-22T19:49:06.334053Z","shell.execute_reply":"2024-12-22T19:49:06.338160Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"RV_Ujy4DmYYU","outputId":"b82c31e3-9ae8-4402-d7b0-a5dc980dd047"},"outputs":[{"name":"stdout","text":"without sitting down and doing it manually you might try some scheduling software there are several here is one that you can download i havent tried it but it seems to do the job nn download the league system pro 30007427 410505040 html tag pdp prod\n......................................................................................\nx rates d usd mxn graph 120 html\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"from tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Embedding, Dropout, Dense, LayerNormalization, MultiHeadAttention, GlobalAveragePooling1D\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\n\n# Combine train and test for tokenization\ncombined = pd.concat([train['Discussion'], test['Discussion']], axis=0)\n\n# Step 2: Tokenization and Word Embedding\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(combined)\n\n# Convert text to sequences\nX_train_seq = tokenizer.texts_to_sequences(train['Discussion'])\nX_test_seq = tokenizer.texts_to_sequences(test['Discussion'])\n\n# Pad sequences to ensure equal length\nmax_seq_length = 250  # Adjust this based on text length analysis\nX_train_padded = pad_sequences(X_train_seq, maxlen=max_seq_length, padding='post')\nX_test_padded = pad_sequences(X_test_seq, maxlen=max_seq_length, padding='post')\n\n# Prepare labels\ny_train = to_categorical(train['Category'].values)  # Convert to one-hot encoding\n\n# Step 3: Split Train Data\nX_train_final, X_val, y_train_final, y_val = train_test_split(\n    X_train_padded, y_train, test_size=0.2, random_state=42, stratify=train['Category']\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T19:49:06.339909Z","iopub.execute_input":"2024-12-22T19:49:06.340230Z","iopub.status.idle":"2024-12-22T19:49:11.433669Z","shell.execute_reply.started":"2024-12-22T19:49:06.340198Z","shell.execute_reply":"2024-12-22T19:49:11.432654Z"},"id":"6ruWQoYdmYYU"},"outputs":[],"execution_count":16},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Embedding, LSTM, Bidirectional, Concatenate\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nimport numpy as np\n\ndef create_transformer_block(inputs, embed_dim, num_heads, ff_dim, dropout=0.1):\n    # Multi-Head Attention\n    attention_output = MultiHeadAttention(\n        num_heads=num_heads, key_dim=embed_dim // num_heads\n    )(inputs, inputs)\n    attention_output = Dropout(dropout)(attention_output)\n    attention_output = LayerNormalization(epsilon=1e-6)(inputs + attention_output)\n\n    # Feed Forward Network\n    ffn_output = Dense(ff_dim, activation=\"relu\")(attention_output)\n    ffn_output = Dense(embed_dim)(ffn_output)\n    ffn_output = Dropout(dropout)(ffn_output)\n    sequence_output = LayerNormalization(epsilon=1e-6)(attention_output + ffn_output)\n\n    return sequence_output\n\n# Model parameters\nvocab_size = len(tokenizer.word_index) + 1\nembed_dim = 256\nnum_heads = 8\nff_dim = 512\nnum_transformer_blocks = 2\nlstm_units = 128\ndropout_rate = 0.2\n\n# Model architecture\ninputs = Input(shape=(max_seq_length,))\n\n# Embedding layer\nembedding_layer = Embedding(\n    input_dim=vocab_size,\n    output_dim=embed_dim,\n    input_length=max_seq_length\n)(inputs)\n\n# Transformer branch\ntransformer_output = embedding_layer\nfor _ in range(num_transformer_blocks):\n    transformer_output = create_transformer_block(\n        transformer_output,\n        embed_dim,\n        num_heads,\n        ff_dim,\n        dropout_rate\n    )\n\n# LSTM branch\nlstm_output = Bidirectional(LSTM(lstm_units, return_sequences=True))(embedding_layer)\nlstm_output = LayerNormalization(epsilon=1e-6)(lstm_output)\nlstm_output = Dropout(dropout_rate)(lstm_output)\n\n# Combine transformer and LSTM branches\ncombined = Concatenate(axis=-1)([transformer_output, lstm_output])\n\n# Final processing\nx = GlobalAveragePooling1D()(combined)\nx = Dense(256, activation=\"relu\")(x)\nx = Dropout(dropout_rate)(x)\nx = LayerNormalization(epsilon=1e-6)(x)\nx = Dense(128, activation=\"relu\")(x)\nx = Dropout(dropout_rate)(x)\noutputs = Dense(y_train.shape[1], activation=\"softmax\")(x)\n\n# Create and compile model\nmodel = Model(inputs=inputs, outputs=outputs)\n\n# Compile with a slower initial learning rate for stability\ninitial_learning_rate = 0.0001\noptimizer = tf.keras.optimizers.Adam(learning_rate=initial_learning_rate)\nmodel.compile(\n    optimizer=optimizer,\n    loss=\"categorical_crossentropy\",\n    metrics=[\"accuracy\"]\n)\n\n# Simplified callback - only early stopping on val_loss\ncallbacks = [\n    EarlyStopping(\n        monitor='val_loss',\n        patience=7,\n        restore_best_weights=True\n    )\n]\n# Train the model\nhistory = model.fit(\n    X_train_final,\n    y_train_final,\n    batch_size=32,\n    epochs=50,\n    validation_data=(X_val, y_val),\n    callbacks=callbacks,\n    verbose=1\n)\n\n# Generate predictions\ntest_predictions = model.predict(X_test_padded)\npredicted_classes = np.argmax(test_predictions, axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T19:49:11.434674Z","iopub.execute_input":"2024-12-22T19:49:11.435323Z","iopub.status.idle":"2024-12-22T19:57:27.042755Z","shell.execute_reply.started":"2024-12-22T19:49:11.435283Z","shell.execute_reply":"2024-12-22T19:57:27.041675Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"MSUaORR-mYYV","outputId":"9e17cd8f-189f-4509-ed77-3c8477f0cb4a"},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/50\n\u001b[1m617/617\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 78ms/step - accuracy: 0.2274 - loss: 1.6626 - val_accuracy: 0.4398 - val_loss: 1.3509\nEpoch 2/50\n\u001b[1m617/617\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 77ms/step - accuracy: 0.4881 - loss: 1.2459 - val_accuracy: 0.6460 - val_loss: 0.9333\nEpoch 3/50\n\u001b[1m617/617\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 77ms/step - accuracy: 0.7115 - loss: 0.7924 - val_accuracy: 0.6937 - val_loss: 0.8803\nEpoch 4/50\n\u001b[1m617/617\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 77ms/step - accuracy: 0.8258 - loss: 0.5160 - val_accuracy: 0.6805 - val_loss: 0.9936\nEpoch 5/50\n\u001b[1m617/617\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 77ms/step - accuracy: 0.8956 - loss: 0.3303 - val_accuracy: 0.6548 - val_loss: 1.2244\nEpoch 6/50\n\u001b[1m617/617\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 77ms/step - accuracy: 0.9312 - loss: 0.2228 - val_accuracy: 0.6637 - val_loss: 1.3686\nEpoch 7/50\n\u001b[1m617/617\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 77ms/step - accuracy: 0.9504 - loss: 0.1619 - val_accuracy: 0.6594 - val_loss: 1.5945\nEpoch 8/50\n\u001b[1m617/617\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 77ms/step - accuracy: 0.9610 - loss: 0.1198 - val_accuracy: 0.6473 - val_loss: 1.7397\nEpoch 9/50\n\u001b[1m617/617\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 77ms/step - accuracy: 0.9677 - loss: 0.1074 - val_accuracy: 0.6497 - val_loss: 1.9946\nEpoch 10/50\n\u001b[1m617/617\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 77ms/step - accuracy: 0.9691 - loss: 0.0942 - val_accuracy: 0.6408 - val_loss: 1.9717\n\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# Create and save submission\nsubmission = pd.DataFrame({\n    'SampleID': test['SampleID'],\n    'Category': predicted_classes\n})\nsubmission.to_csv('hybrid_transformer_lstm_predictions333.csv', index=False)\n","metadata":{"id":"0Y1kol0tx3MU","trusted":true,"execution":{"iopub.status.busy":"2024-12-22T19:59:17.024744Z","iopub.execute_input":"2024-12-22T19:59:17.025183Z","iopub.status.idle":"2024-12-22T19:59:17.038670Z","shell.execute_reply.started":"2024-12-22T19:59:17.025157Z","shell.execute_reply":"2024-12-22T19:59:17.037806Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"final_train_loss, final_train_accuracy = model.evaluate(X_train_final, y_train_final, verbose=0)\nfinal_val_loss, final_val_accuracy = model.evaluate(X_val, y_val, verbose=0)\n\nprint(f\"\\nFinal Training Accuracy: {final_train_accuracy:.4f}\")\nprint(f\"Final Validation Accuracy: {final_val_accuracy:.4f}\")","metadata":{"id":"pk5NsDjqx3nR","trusted":true,"execution":{"iopub.status.busy":"2024-12-22T19:57:27.059202Z","iopub.execute_input":"2024-12-22T19:57:27.059503Z","iopub.status.idle":"2024-12-22T19:57:45.515684Z","shell.execute_reply.started":"2024-12-22T19:57:27.059471Z","shell.execute_reply":"2024-12-22T19:57:45.514857Z"}},"outputs":[{"name":"stdout","text":"\nFinal Training Accuracy: 0.8457\nFinal Validation Accuracy: 0.6937\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# Save the whole model to a file\nmodel.save('hybird_transformer_model.h5')\nprint(\"Model saving is done\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T20:02:33.756193Z","iopub.execute_input":"2024-12-22T20:02:33.756547Z","iopub.status.idle":"2024-12-22T20:02:34.522682Z","shell.execute_reply.started":"2024-12-22T20:02:33.756524Z","shell.execute_reply":"2024-12-22T20:02:34.521882Z"}},"outputs":[{"name":"stdout","text":"Model saving is done\n","output_type":"stream"}],"execution_count":21}]}